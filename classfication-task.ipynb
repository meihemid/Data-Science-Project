{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "</style>\n",
    "<h1  style=\"text-align:center;font-size:60px\">  Machine Learning Projects\n",
    "    <h2 style=\"text-align:center\">Classification Dataset : Drug Consumption</h2>\n",
    "    <br><br>\n",
    "    <h2 style=\"text-align:left;font-size:20px\">\n",
    "        <u> Date:</u> April 2021 <br><br>\n",
    "        <u> Groupe 24:</u><br><br>\n",
    "          <li>Anas Krichel ( anas.krichel@telecom-paris.fr )</li>\n",
    "          <li>Maha Meihemid ( meihemid.meihemid@telecom-paris.fr )</li>\n",
    "          <li>Louis Dorge ( ldorge@telecom-paris.fr )</li><br> \n",
    "     </h2>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II.Data Set : drug_consumption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Set Informartion :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Database contains records for 1885 respondents. For each respondent 12 attributes are known: Personality measurements which include NEO-FFI-R (neuroticism, extraversion, openness to experience, agreeableness, and conscientiousness), BIS-11 (impulsivity), and ImpSS (sensation seeking), level of education, age, gender, country of residence and ethnicity. All input attributes are originally categorical and are quantified. After quantification values of all input features can be considered as real-valued. In addition, participants were questioned concerning their use of 18 legal and illegal drugs (alcohol, amphetamines, amyl nitrite, benzodiazepine, cannabis, chocolate, cocaine, caffeine, crack, ecstasy, heroin, ketamine, legal highs, LSD, methadone, mushrooms, nicotine and volatile substance abuse and one fictitious drug (Semeron) which was introduced to identify over-claimers. For each drug they have to select one of the answers: never used the drug, used it over a decade ago, or in the last decade, year, month, week, or day.\n",
    "Database contains 18 classification problems. Each of independent label variables contains seven classes: \"Never Used\", \"Used over a Decade Ago\", \"Used in Last Decade\", \"Used in Last Year\", \"Used in Last Month\", \"Used in Last Week\", and \"Used in Last Day\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " DataSet website: https://archive.ics.uci.edu/ml/datasets/Drug+consumption+%28quantified%29"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II-1.dataset analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "libraries are imported\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "np.random.seed(1234)# fixer la  graine du générateur de nombres pseudo-aléatoires.\n",
    "print(\"libraries are imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's name our columns after analysis data-sheet from dataset source\n",
    "columns_name = ['ID', 'Age', 'Gender', 'Education', 'Country', 'Ethnicity', 'Neuroticism', 'Extraversion', 'Openness', 'Agreeableness', 'Conscientiousness', 'Impulsiveness', 'Sensation_seeking', 'Alcohol', 'Amphetamine', 'Amyl_nitrite', 'Benzodiazepine', 'Caffeine', 'Cannabis', 'Chocolate', 'Cocaine', 'Crack', 'Ecstasy', 'Heroin', 'Ketamine', 'Legal_highs', 'LSD', 'Methadone', 'Mushrooms', 'Nicotine', 'Semeron', 'VSA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('drug_consumption.data', header = None, names = columns_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking one outputs to predict like what was said on ecampus (this dataset contains multiple outputs to predict in parallel: please pick only one)), so we choose 'Cannabis'\n",
    "df=df[['ID', 'Age', 'Gender', 'Education', 'Country', 'Ethnicity', 'Neuroticism', 'Extraversion', 'Openness', 'Agreeableness', 'Conscientiousness', 'Impulsiveness', 'Sensation_seeking', 'Cannabis']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'Age', 'Gender', 'Education', 'Country', 'Ethnicity',\n",
      "       'Neuroticism', 'Extraversion', 'Openness', 'Agreeableness',\n",
      "       'Conscientiousness', 'Impulsiveness', 'Sensation_seeking', 'Cannabis'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Create a variable containing all the columns/features names\n",
    "data_columns = df.columns\n",
    "print(data_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ID                   0\n",
       "Age                  0\n",
       "Gender               0\n",
       "Education            0\n",
       "Country              0\n",
       "Ethnicity            0\n",
       "Neuroticism          0\n",
       "Extraversion         0\n",
       "Openness             0\n",
       "Agreeableness        0\n",
       "Conscientiousness    0\n",
       "Impulsiveness        0\n",
       "Sensation_seeking    0\n",
       "Cannabis             0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of the dataset: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Education</th>\n",
       "      <th>Country</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Neuroticism</th>\n",
       "      <th>Extraversion</th>\n",
       "      <th>Openness</th>\n",
       "      <th>Agreeableness</th>\n",
       "      <th>Conscientiousness</th>\n",
       "      <th>Impulsiveness</th>\n",
       "      <th>Sensation_seeking</th>\n",
       "      <th>Cannabis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.49788</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>-0.05921</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>0.12600</td>\n",
       "      <td>0.31287</td>\n",
       "      <td>-0.57545</td>\n",
       "      <td>-0.58331</td>\n",
       "      <td>-0.91699</td>\n",
       "      <td>-0.00665</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>-1.18084</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.07854</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>1.98437</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.67825</td>\n",
       "      <td>1.93886</td>\n",
       "      <td>1.43533</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>-0.14277</td>\n",
       "      <td>-0.71126</td>\n",
       "      <td>-0.21575</td>\n",
       "      <td>CL4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.49788</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.05921</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.46725</td>\n",
       "      <td>0.80523</td>\n",
       "      <td>-0.84732</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>-1.01450</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>0.40148</td>\n",
       "      <td>CL3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.95197</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>1.16365</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.14882</td>\n",
       "      <td>-0.80615</td>\n",
       "      <td>-0.01928</td>\n",
       "      <td>0.59042</td>\n",
       "      <td>0.58489</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>-1.18084</td>\n",
       "      <td>CL2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.49788</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>1.98437</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>0.73545</td>\n",
       "      <td>-1.63340</td>\n",
       "      <td>-0.45174</td>\n",
       "      <td>-0.30172</td>\n",
       "      <td>1.30612</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>-0.21575</td>\n",
       "      <td>CL3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID      Age   Gender  Education  Country  Ethnicity  Neuroticism  \\\n",
       "0   1  0.49788  0.48246   -0.05921  0.96082    0.12600      0.31287   \n",
       "1   2 -0.07854 -0.48246    1.98437  0.96082   -0.31685     -0.67825   \n",
       "2   3  0.49788 -0.48246   -0.05921  0.96082   -0.31685     -0.46725   \n",
       "3   4 -0.95197  0.48246    1.16365  0.96082   -0.31685     -0.14882   \n",
       "4   5  0.49788  0.48246    1.98437  0.96082   -0.31685      0.73545   \n",
       "\n",
       "   Extraversion  Openness  Agreeableness  Conscientiousness  Impulsiveness  \\\n",
       "0      -0.57545  -0.58331       -0.91699           -0.00665       -0.21712   \n",
       "1       1.93886   1.43533        0.76096           -0.14277       -0.71126   \n",
       "2       0.80523  -0.84732       -1.62090           -1.01450       -1.37983   \n",
       "3      -0.80615  -0.01928        0.59042            0.58489       -1.37983   \n",
       "4      -1.63340  -0.45174       -0.30172            1.30612       -0.21712   \n",
       "\n",
       "   Sensation_seeking Cannabis  \n",
       "0           -1.18084      CL0  \n",
       "1           -0.21575      CL4  \n",
       "2            0.40148      CL3  \n",
       "3           -1.18084      CL2  \n",
       "4           -0.21575      CL3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"\"\"Missing Values: \"\"\")\n",
    "display(df.isna().sum())\n",
    "print(f\"\"\"Sample of the dataset: \"\"\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there are no missing values in the data, and all output attributes are coded as categorical data that will require preprocessing. The ID column is redundant in this data mining exercise.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the ID column from dataset\n",
    "df.drop(columns=\"ID\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Education</th>\n",
       "      <th>Country</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Neuroticism</th>\n",
       "      <th>Extraversion</th>\n",
       "      <th>Openness</th>\n",
       "      <th>Agreeableness</th>\n",
       "      <th>Conscientiousness</th>\n",
       "      <th>Impulsiveness</th>\n",
       "      <th>Sensation_seeking</th>\n",
       "      <th>Cannabis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.49788</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>-0.05921</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>0.12600</td>\n",
       "      <td>0.31287</td>\n",
       "      <td>-0.57545</td>\n",
       "      <td>-0.58331</td>\n",
       "      <td>-0.91699</td>\n",
       "      <td>-0.00665</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>-1.18084</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.07854</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>1.98437</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.67825</td>\n",
       "      <td>1.93886</td>\n",
       "      <td>1.43533</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>-0.14277</td>\n",
       "      <td>-0.71126</td>\n",
       "      <td>-0.21575</td>\n",
       "      <td>CL4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.49788</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.05921</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.46725</td>\n",
       "      <td>0.80523</td>\n",
       "      <td>-0.84732</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>-1.01450</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>0.40148</td>\n",
       "      <td>CL3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.95197</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>1.16365</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.14882</td>\n",
       "      <td>-0.80615</td>\n",
       "      <td>-0.01928</td>\n",
       "      <td>0.59042</td>\n",
       "      <td>0.58489</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>-1.18084</td>\n",
       "      <td>CL2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.49788</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>1.98437</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>0.73545</td>\n",
       "      <td>-1.63340</td>\n",
       "      <td>-0.45174</td>\n",
       "      <td>-0.30172</td>\n",
       "      <td>1.30612</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>-0.21575</td>\n",
       "      <td>CL3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age   Gender  Education  Country  Ethnicity  Neuroticism  Extraversion  \\\n",
       "0  0.49788  0.48246   -0.05921  0.96082    0.12600      0.31287      -0.57545   \n",
       "1 -0.07854 -0.48246    1.98437  0.96082   -0.31685     -0.67825       1.93886   \n",
       "2  0.49788 -0.48246   -0.05921  0.96082   -0.31685     -0.46725       0.80523   \n",
       "3 -0.95197  0.48246    1.16365  0.96082   -0.31685     -0.14882      -0.80615   \n",
       "4  0.49788  0.48246    1.98437  0.96082   -0.31685      0.73545      -1.63340   \n",
       "\n",
       "   Openness  Agreeableness  Conscientiousness  Impulsiveness  \\\n",
       "0  -0.58331       -0.91699           -0.00665       -0.21712   \n",
       "1   1.43533        0.76096           -0.14277       -0.71126   \n",
       "2  -0.84732       -1.62090           -1.01450       -1.37983   \n",
       "3  -0.01928        0.59042            0.58489       -1.37983   \n",
       "4  -0.45174       -0.30172            1.30612       -0.21712   \n",
       "\n",
       "   Sensation_seeking Cannabis  \n",
       "0           -1.18084      CL0  \n",
       "1           -0.21575      CL4  \n",
       "2            0.40148      CL3  \n",
       "3           -1.18084      CL2  \n",
       "4           -0.21575      CL3  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#returns the first 5 rows of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Count of Different Classes Vs Cannabis\"\n",
    "fig, axes = plt.subplots(1,1)\n",
    "fig.suptitle(\"Count of Different Classes Vs Cannabis\")\n",
    "sns.countplot(x='Cannabis', data=df)    \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                 -0.036269\n",
       "Gender               0.235378\n",
       "Education            0.160696\n",
       "Country              0.306935\n",
       "Ethnicity           -0.121806\n",
       "Neuroticism          0.050112\n",
       "Extraversion         0.024334\n",
       "Openness             0.108904\n",
       "Agreeableness        0.013278\n",
       "Conscientiousness    0.065540\n",
       "Impulsiveness        0.139896\n",
       "Sensation_seeking    0.120540\n",
       "Cannabis             1.000000\n",
       "Name: Cannabis, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Study of the CORRELATION BETWEEN variables and cannabis\n",
    "cannabis_corr=df.apply(lambda x : pd.factorize(x)[0]).corr(method='pearson')\n",
    "#cannabis_corr\n",
    "cannabis_corr['Cannabis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_data = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = ['18-24' if a <= -0.9 else \n",
    "       '25-34' if a >= -0.5 and a < 0 else \n",
    "       '35-44' if a > 0 and a < 1 else \n",
    "       '45-54' if a > 1 and a < 1.5 else \n",
    "       '55-64' if a > 1.5 and a < 2 else \n",
    "       '65+' \n",
    "       for a in demo_data['Age']]\n",
    "\n",
    "gender = ['Female' if g > 0 else \"Male\" for g in demo_data['Gender']]\n",
    "\n",
    "education = ['Left school before 16 years' if e <-2 else \n",
    "             'Left school at 16 years' if e > -2 and e < -1.5 else \n",
    "             'Left school at 17 years' if e > -1.5 and e < -1.4 else \n",
    "             'Left school at 18 years' if e > -1.4 and e < -1 else \n",
    "             'Some college or university, no certificate or degree' if e > -1 and e < -0.5 else \n",
    "             'Professional certificate/ diploma' if e > -0.5 and e < 0 else \n",
    "             'University degree' if e > 0 and e < 0.5 else \n",
    "             'Masters degree' if e > 0.5 and e < 1.5 else \n",
    "             'Doctorate degree' \n",
    "             for e in demo_data['Education']]\n",
    "\n",
    "country = ['USA' if c < -0.5 else \n",
    "           'New Zealand' if c > -0.5 and c < -0.4 else \n",
    "           'Other' if c > -0.4 and c < -0.2 else \n",
    "           'Australia' if c > -0.2 and c < 0 else \n",
    "           'Ireland' if c > 0 and c < 0.23 else \n",
    "           'Canada' if c > 0.23 and c < 0.9 else \n",
    "           'UK' \n",
    "           for c in demo_data['Country']]\n",
    "\n",
    "ethnicity = ['Black' if e < -1 else \n",
    "             'Asian' if e > -1 and e < -0.4 else \n",
    "             'White' if e > -0.4 and e < -0.25 else \n",
    "             'Mixed-White/Black' if e >= -0.25 and e < 0.11 else \n",
    "             'Mixed-White/Asian' if e > 0.12 and e < 1 else \n",
    "             'Mixed-Black/Asian' if e > 1.9 else \n",
    "             'Other' \n",
    "             for e in demo_data['Ethnicity']]\n",
    "\n",
    "\n",
    "demo_data['Age'] = age\n",
    "demo_data['Gender'] = gender\n",
    "demo_data['Education'] = education\n",
    "demo_data['Country'] = country\n",
    "demo_data['Ethnicity'] = ethnicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_counts_percentage(dataset, column):\n",
    "    ''' value.counts() method extended by displaying percentage '''\n",
    "    \n",
    "    a = dataset[column].value_counts()\n",
    "    b = dataset[column].value_counts(normalize=True) * 100\n",
    "    \n",
    "    return pd.concat([a,b.round(2)], axis=1, keys=['N', '%'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Male</th>\n",
       "      <td>943</td>\n",
       "      <td>50.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Female</th>\n",
       "      <td>942</td>\n",
       "      <td>49.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          N      %\n",
       "Male    943  50.03\n",
       "Female  942  49.97"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Gender\n",
    "value_counts_percentage(demo_data, 'Gender')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### comment : There is nearly the same number of male and female participants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18-24</th>\n",
       "      <td>643</td>\n",
       "      <td>34.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25-34</th>\n",
       "      <td>481</td>\n",
       "      <td>25.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35-44</th>\n",
       "      <td>356</td>\n",
       "      <td>18.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45-54</th>\n",
       "      <td>294</td>\n",
       "      <td>15.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55-64</th>\n",
       "      <td>93</td>\n",
       "      <td>4.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65+</th>\n",
       "      <td>18</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         N      %\n",
       "18-24  643  34.11\n",
       "25-34  481  25.52\n",
       "35-44  356  18.89\n",
       "45-54  294  15.60\n",
       "55-64   93   4.93\n",
       "65+     18   0.95"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Age\n",
    "value_counts_percentage(demo_data, 'Age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### comment : The age is given in the intervals of about 10 years.\n",
    "\n",
    "18-24 is the biggest age group (about 1/3 of all participants).\n",
    "\n",
    "25-34 is 1/4 of participants.\n",
    "\n",
    "35-54 is another 1/3 of participants. The rest 5% are the people above 55 y.o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x299a194b940>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='Age', palette='ch:.25', data=demo_data.sort_values(by=['Age']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Some college or university, no certificate or degree</th>\n",
       "      <td>506</td>\n",
       "      <td>26.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>University degree</th>\n",
       "      <td>480</td>\n",
       "      <td>25.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Masters degree</th>\n",
       "      <td>283</td>\n",
       "      <td>15.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Professional certificate/ diploma</th>\n",
       "      <td>270</td>\n",
       "      <td>14.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Left school at 18 years</th>\n",
       "      <td>100</td>\n",
       "      <td>5.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Left school at 16 years</th>\n",
       "      <td>99</td>\n",
       "      <td>5.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doctorate degree</th>\n",
       "      <td>89</td>\n",
       "      <td>4.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Left school at 17 years</th>\n",
       "      <td>30</td>\n",
       "      <td>1.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Left school before 16 years</th>\n",
       "      <td>28</td>\n",
       "      <td>1.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      N      %\n",
       "Some college or university, no certificate or d...  506  26.84\n",
       "University degree                                   480  25.46\n",
       "Masters degree                                      283  15.01\n",
       "Professional certificate/ diploma                   270  14.32\n",
       "Left school at 18 years                             100   5.31\n",
       "Left school at 16 years                              99   5.25\n",
       "Doctorate degree                                     89   4.72\n",
       "Left school at 17 years                              30   1.59\n",
       "Left school before 16 years                          28   1.49"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Education\n",
    "value_counts_percentage(demo_data, 'Education')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### comment :Educated people predominate (with college and above level - about 85% of all). Other people finished their education up to 18 y.o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x299a194b0d0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "edu_plot = sns.countplot(x='Education', palette='ch:.25', data=demo_data.sort_values(by=['Education']))\n",
    "edu_plot.set_xticklabels(edu_plot.get_xticklabels(), rotation=40, ha=\"right\")\n",
    "edu_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>White</th>\n",
       "      <td>1720</td>\n",
       "      <td>91.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>63</td>\n",
       "      <td>3.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Black</th>\n",
       "      <td>33</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Asian</th>\n",
       "      <td>26</td>\n",
       "      <td>1.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mixed-White/Black</th>\n",
       "      <td>20</td>\n",
       "      <td>1.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mixed-White/Asian</th>\n",
       "      <td>20</td>\n",
       "      <td>1.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mixed-Black/Asian</th>\n",
       "      <td>3</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      N      %\n",
       "White              1720  91.25\n",
       "Other                63   3.34\n",
       "Black                33   1.75\n",
       "Asian                26   1.38\n",
       "Mixed-White/Black    20   1.06\n",
       "Mixed-White/Asian    20   1.06\n",
       "Mixed-Black/Asian     3   0.16"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ethnicity\n",
    "value_counts_percentage(demo_data, 'Ethnicity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### comment : Over 90% of participants are white people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>UK</th>\n",
       "      <td>1044</td>\n",
       "      <td>55.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USA</th>\n",
       "      <td>557</td>\n",
       "      <td>29.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>118</td>\n",
       "      <td>6.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Canada</th>\n",
       "      <td>87</td>\n",
       "      <td>4.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia</th>\n",
       "      <td>54</td>\n",
       "      <td>2.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ireland</th>\n",
       "      <td>20</td>\n",
       "      <td>1.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Zealand</th>\n",
       "      <td>5</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                N      %\n",
       "UK           1044  55.38\n",
       "USA           557  29.55\n",
       "Other         118   6.26\n",
       "Canada         87   4.62\n",
       "Australia      54   2.86\n",
       "Ireland        20   1.06\n",
       "New Zealand     5   0.27"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Country\n",
    "value_counts_percentage(demo_data, 'Country')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### comment : All countries are officially English-speaking.\n",
    "\n",
    "Over 50% of participants come from the UK, almost 1/3 from the USA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Country</th>\n",
       "      <th>Australia</th>\n",
       "      <th>Canada</th>\n",
       "      <th>Ireland</th>\n",
       "      <th>New Zealand</th>\n",
       "      <th>Other</th>\n",
       "      <th>UK</th>\n",
       "      <th>USA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cannabis</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CL0</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>366</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CL1</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>177</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CL2</th>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>194</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CL3</th>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>104</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CL4</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>38</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CL5</th>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>58</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CL6</th>\n",
       "      <td>15</td>\n",
       "      <td>27</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>107</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Country   Australia  Canada  Ireland  New Zealand  Other   UK  USA\n",
       "Cannabis                                                          \n",
       "CL0               2      13        3            0     12  366   17\n",
       "CL1               3       7        1            0      6  177   13\n",
       "CL2               6      12        1            1     13  194   39\n",
       "CL3               9      11        2            0     13  104   72\n",
       "CL4               9       9        3            2     12   38   67\n",
       "CL5              10       8        2            0     22   58   85\n",
       "CL6              15      27        8            2     40  107  264"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compute a simple cross-tabulation  between 'Cannabis' and 'Country'\n",
    "pd.crosstab(demo_data['Cannabis'],demo_data['Country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Education</th>\n",
       "      <th>Doctorate degree</th>\n",
       "      <th>Left school at 16 years</th>\n",
       "      <th>Left school at 17 years</th>\n",
       "      <th>Left school at 18 years</th>\n",
       "      <th>Left school before 16 years</th>\n",
       "      <th>Masters degree</th>\n",
       "      <th>Professional certificate/ diploma</th>\n",
       "      <th>Some college or university, no certificate or degree</th>\n",
       "      <th>University degree</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cannabis</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CL0</th>\n",
       "      <td>25</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>81</td>\n",
       "      <td>82</td>\n",
       "      <td>33</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CL1</th>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>33</td>\n",
       "      <td>20</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CL2</th>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "      <td>37</td>\n",
       "      <td>45</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CL3</th>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>27</td>\n",
       "      <td>56</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CL4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>64</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CL5</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>21</td>\n",
       "      <td>81</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CL6</th>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "      <td>31</td>\n",
       "      <td>50</td>\n",
       "      <td>207</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Education  Doctorate degree  Left school at 16 years  Left school at 17 years  \\\n",
       "Cannabis                                                                        \n",
       "CL0                      25                       34                        5   \n",
       "CL1                      16                       10                        2   \n",
       "CL2                      17                       11                        3   \n",
       "CL3                      11                        8                        6   \n",
       "CL4                       4                        5                        1   \n",
       "CL5                       7                        8                        5   \n",
       "CL6                       9                       23                        8   \n",
       "\n",
       "Education  Left school at 18 years  Left school before 16 years  \\\n",
       "Cannabis                                                          \n",
       "CL0                             14                            6   \n",
       "CL1                              9                            2   \n",
       "CL2                              8                            2   \n",
       "CL3                              5                            4   \n",
       "CL4                             11                            1   \n",
       "CL5                             13                            2   \n",
       "CL6                             40                           11   \n",
       "\n",
       "Education  Masters degree  Professional certificate/ diploma  \\\n",
       "Cannabis                                                       \n",
       "CL0                    81                                 82   \n",
       "CL1                    60                                 33   \n",
       "CL2                    55                                 37   \n",
       "CL3                    29                                 27   \n",
       "CL4                    11                                 20   \n",
       "CL5                    16                                 21   \n",
       "CL6                    31                                 50   \n",
       "\n",
       "Education  Some college or university, no certificate or degree  \\\n",
       "Cannabis                                                          \n",
       "CL0                                                       33      \n",
       "CL1                                                       20      \n",
       "CL2                                                       45      \n",
       "CL3                                                       56      \n",
       "CL4                                                       64      \n",
       "CL5                                                       81      \n",
       "CL6                                                      207      \n",
       "\n",
       "Education  University degree  \n",
       "Cannabis                      \n",
       "CL0                      133  \n",
       "CL1                       55  \n",
       "CL2                       88  \n",
       "CL3                       65  \n",
       "CL4                       23  \n",
       "CL5                       32  \n",
       "CL6                       84  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compute a simple cross-tabulation  between 'Cannabis' and 'Education'\n",
    "pd.crosstab(demo_data['Cannabis'],demo_data['Education'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Asian</th>\n",
       "      <th>Black</th>\n",
       "      <th>Mixed-Black/Asian</th>\n",
       "      <th>Mixed-White/Asian</th>\n",
       "      <th>Mixed-White/Black</th>\n",
       "      <th>Other</th>\n",
       "      <th>White</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cannabis</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CL0</th>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CL1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CL2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CL3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CL4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CL5</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CL6</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Ethnicity  Asian  Black  Mixed-Black/Asian  Mixed-White/Asian  \\\n",
       "Cannabis                                                        \n",
       "CL0           16     23                  0                  3   \n",
       "CL1            3      0                  0                  1   \n",
       "CL2            3      2                  0                  4   \n",
       "CL3            1      1                  0                  0   \n",
       "CL4            1      1                  1                  3   \n",
       "CL5            0      4                  0                  2   \n",
       "CL6            2      2                  2                  7   \n",
       "\n",
       "Ethnicity  Mixed-White/Black  Other  White  \n",
       "Cannabis                                    \n",
       "CL0                        5     11    355  \n",
       "CL1                        1      2    200  \n",
       "CL2                        5      4    248  \n",
       "CL3                        1      6    202  \n",
       "CL4                        1     11    122  \n",
       "CL5                        4      4    171  \n",
       "CL6                        3     25    422  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compute a simple cross-tabulation  between 'Cannabis' and 'Ethnicity'\n",
    "pd.crosstab(demo_data['Cannabis'],demo_data['Ethnicity'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Country</th>\n",
       "      <th>Australia</th>\n",
       "      <th>Canada</th>\n",
       "      <th>Ireland</th>\n",
       "      <th>New Zealand</th>\n",
       "      <th>Other</th>\n",
       "      <th>UK</th>\n",
       "      <th>USA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cannabis</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CL0</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>366</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CL1</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>177</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CL2</th>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>194</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CL3</th>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>104</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CL4</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>38</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CL5</th>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>58</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CL6</th>\n",
       "      <td>15</td>\n",
       "      <td>27</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>107</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Country   Australia  Canada  Ireland  New Zealand  Other   UK  USA\n",
       "Cannabis                                                          \n",
       "CL0               2      13        3            0     12  366   17\n",
       "CL1               3       7        1            0      6  177   13\n",
       "CL2               6      12        1            1     13  194   39\n",
       "CL3               9      11        2            0     13  104   72\n",
       "CL4               9       9        3            2     12   38   67\n",
       "CL5              10       8        2            0     22   58   85\n",
       "CL6              15      27        8            2     40  107  264"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compute a simple cross-tabulation  between 'Cannabis' and 'Country'\n",
    "pd.crosstab(demo_data['Cannabis'],demo_data['Country'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II-2.Binarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copy of the data \n",
    "binary_df = df.copy()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class=CL0, n=413 (21.910%)\n",
      "Class=CL4, n=140 (7.427%)\n",
      "Class=CL3, n=211 (11.194%)\n",
      "Class=CL2, n=266 (14.111%)\n",
      "Class=CL1, n=207 (10.981%)\n",
      "Class=CL6, n=463 (24.562%)\n",
      "Class=CL5, n=185 (9.814%)\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "y= binary_df['Cannabis']\n",
    "counter = Counter(y)\n",
    "for k,v in counter.items():\n",
    "    per = v / len(y) * 100\n",
    "    print('Class=%s, n=%d (%.3f%%)' % (k, v, per))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem can be transformed to binary classification by union of part of classes into one new class. For example, \"Never Used\", \"Used over a Decade Ago\", \"Used in Last Decade\" form class \"Non-user\" and all other classes form class \"User\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the multiclass problem into a binary classfication\n",
    "def multi_to_bin(x):\n",
    "    \n",
    "    if (x == 'CL0') :\n",
    "        x = 0\n",
    "    if (x == 'CL1') :\n",
    "        x = 0\n",
    "    if (x == 'CL2') :\n",
    "        x = 0\n",
    "    if (x == 'CL3') :\n",
    "        x = 1\n",
    "    if (x == 'CL4') :\n",
    "        x = 1\n",
    "    if (x == 'CL5') :\n",
    "        x = 1\n",
    "    if (x == 'CL6') :\n",
    "        x = 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying our changes in classification of drug consumption to 'Cannabis' column\n",
    "binary_df['Cannabis'] = binary_df['Cannabis'].map(multi_to_bin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Education</th>\n",
       "      <th>Country</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Neuroticism</th>\n",
       "      <th>Extraversion</th>\n",
       "      <th>Openness</th>\n",
       "      <th>Agreeableness</th>\n",
       "      <th>Conscientiousness</th>\n",
       "      <th>Impulsiveness</th>\n",
       "      <th>Sensation_seeking</th>\n",
       "      <th>Cannabis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.49788</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>-0.05921</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>0.12600</td>\n",
       "      <td>0.31287</td>\n",
       "      <td>-0.57545</td>\n",
       "      <td>-0.58331</td>\n",
       "      <td>-0.91699</td>\n",
       "      <td>-0.00665</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>-1.18084</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.07854</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>1.98437</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.67825</td>\n",
       "      <td>1.93886</td>\n",
       "      <td>1.43533</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>-0.14277</td>\n",
       "      <td>-0.71126</td>\n",
       "      <td>-0.21575</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.49788</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.05921</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.46725</td>\n",
       "      <td>0.80523</td>\n",
       "      <td>-0.84732</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>-1.01450</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>0.40148</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.95197</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>1.16365</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.14882</td>\n",
       "      <td>-0.80615</td>\n",
       "      <td>-0.01928</td>\n",
       "      <td>0.59042</td>\n",
       "      <td>0.58489</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>-1.18084</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.49788</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>1.98437</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>0.73545</td>\n",
       "      <td>-1.63340</td>\n",
       "      <td>-0.45174</td>\n",
       "      <td>-0.30172</td>\n",
       "      <td>1.30612</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>-0.21575</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age   Gender  Education  Country  Ethnicity  Neuroticism  Extraversion  \\\n",
       "0  0.49788  0.48246   -0.05921  0.96082    0.12600      0.31287      -0.57545   \n",
       "1 -0.07854 -0.48246    1.98437  0.96082   -0.31685     -0.67825       1.93886   \n",
       "2  0.49788 -0.48246   -0.05921  0.96082   -0.31685     -0.46725       0.80523   \n",
       "3 -0.95197  0.48246    1.16365  0.96082   -0.31685     -0.14882      -0.80615   \n",
       "4  0.49788  0.48246    1.98437  0.96082   -0.31685      0.73545      -1.63340   \n",
       "\n",
       "   Openness  Agreeableness  Conscientiousness  Impulsiveness  \\\n",
       "0  -0.58331       -0.91699           -0.00665       -0.21712   \n",
       "1   1.43533        0.76096           -0.14277       -0.71126   \n",
       "2  -0.84732       -1.62090           -1.01450       -1.37983   \n",
       "3  -0.01928        0.59042            0.58489       -1.37983   \n",
       "4  -0.45174       -0.30172            1.30612       -0.21712   \n",
       "\n",
       "   Sensation_seeking  Cannabis  \n",
       "0           -1.18084         0  \n",
       "1           -0.21575         1  \n",
       "2            0.40148         1  \n",
       "3           -1.18084         0  \n",
       "4           -0.21575         1  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#returns the first 5 rows of the dataframe\n",
    "binary_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ML Models Binary Classfication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating features and the target\n",
    "# dataset on Cannabis target\n",
    "y = binary_df['Cannabis']\n",
    "X = binary_df.drop(['Cannabis'], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Centred the data\n",
    "X_train = StandardScaler().fit_transform(X_train)\n",
    "X_test = StandardScaler().fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Classifier 1 : Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision tree is the most powerful and popular tool for classification and prediction. A Decision tree is a flowchart like tree structure, where each internal node denotes a test on an attribute, each branch represents an outcome of the test, and each leaf node (terminal node) holds a class label.\n",
    "\n",
    "A tree can be “learned” by splitting the source set into subsets based on an attribute value test. This process is repeated on each derived subset in a recursive manner called recursive partitioning. The recursion is completed when the subset at a node all has the same value of the target variable, or when splitting no longer adds value to the predictions.\n",
    "\n",
    "Due to Decision trees can handle high dimensional data and in general decision tree classifier has good accuracy, we are going to begin by test this model because the construction of decision tree classifier does not require any domain knowledge or parameter setting, and therefore is appropriate for exploratory knowledge discovery."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### So we are going to test the model of decision tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0 = DecisionTreeClassifier()\n",
    "model_0.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score for train data :  1.0\n",
      "roc_auc for train data :  1.0\n",
      "average_precision train data :  1.0\n",
      "accuracy train data :  1.0\n",
      "precision train data :  1.0\n",
      "recall train data :  1.0\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_0.predict(X_train)\n",
    "print('f1_score for train data : ',metrics.f1_score(y_train, y_pred))\n",
    "print('roc_auc for train data : ',metrics.roc_auc_score(y_train, y_pred))\n",
    "print('average_precision train data : ',metrics.average_precision_score(y_train, y_pred))\n",
    "print('accuracy train data : ',metrics.accuracy_score(y_train, y_pred))\n",
    "print('precision train data : ',metrics.precision_score(y_train, y_pred))\n",
    "print('recall train data : ',metrics.recall_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score for test data :  0.7741935483870969\n",
      "roc_auc for test data :  0.7623783783783784\n",
      "average_precision test data :  0.722295990078545\n",
      "accuracy test data :  0.7627118644067796\n",
      "precision test data :  0.7804878048780488\n",
      "recall test data :  0.768\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_0.predict(X_test)\n",
    "print('f1_score for test data : ',metrics.f1_score(y_test, y_pred))\n",
    "print('roc_auc for test data : ',metrics.roc_auc_score(y_test, y_pred))\n",
    "print('average_precision test data : ',metrics.average_precision_score(y_test, y_pred))\n",
    "print('accuracy test data : ',metrics.accuracy_score(y_test, y_pred))\n",
    "print('precision test data : ',metrics.precision_score(y_test, y_pred))\n",
    "print('recall test data : ',metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running this first model we have been able to observe that the accuracy of the model is 0.75; which is a good score to start ; however it is necessary to improve it a little more.\n",
    "\n",
    "Thanks to ours resultats we observed Decision trees are able to generate understandable rules and perform classification without requiring much computation.\n",
    "\n",
    "Althought Decision trees are able to handle both continuous and categorical variables. Decision trees provide a clear indication of which fields are most important for prediction or classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Notice "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then when using a decision tree model on a given training dataset the accuracy keeps improving with more and more splits. So we can easily overfit the data and doesn't know when you have crossed the line unless you are using cross validation (on training data set).\n",
    "\n",
    "However the advantage of a simple decision tree is model is easy to interpret, you know what variable and what value of that variable is used to split the data and predict outcome.\n",
    "\n",
    "While a random forest is like a black box and works as mentioned in above answer. It's a forest you can build and control the number of trees you want and specify max num of features to be used in each tree But you cannot control the randomness, you cannot control which feature is part of which tree in the forest\n",
    "\n",
    "So if we apply the Random Forest the accuracy will increase because this will reduce variance part of error rather than bias part, so on a given training data set decision tree may be more accurate than a random forest. But on an unexpected validation data set, Random forest always wins in terms of accuracy.\n",
    "\n",
    "Then we are going this model in the following classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Classifier 2:  Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we are going to apply Random forest,which consists of a large number of individual decision trees that operate as an ensemble and  \n",
    "each individual tree in the random forest spits out a class prediction and the class with the most votes becomes our model’s prediction .\n",
    "Each individual tree to try to create an uncorrelated forest of trees whose prediction by committee is more accurate than that of any individual tree.\n",
    "\n",
    "However the fundamental concept behind random forest is a simple but powerful one — the wisdom of crowds. In data science speak, the reason that the random forest model works so well is:\n",
    "A large number of relatively uncorrelated models (trees) operating as a committee will outperform any of the individual constituent models.\n",
    "\n",
    "For this reason  is that the trees protect each other from their individual errors (as long as they don’t constantly all err in the same direction). While some trees may be wrong, many other trees will be right, so as a group the trees are able to move in the correct direction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  Random Forest without parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score for train data :  1.0\n",
      "roc_auc for train data :  1.0\n",
      "average_precision train data :  1.0\n",
      "accuracy train data :  1.0\n",
      "precision train data :  1.0\n",
      "recall train data :  1.0\n"
     ]
    }
   ],
   "source": [
    "y_pred = rfc.predict(X_train)\n",
    "print('f1_score for train data : ',metrics.f1_score(y_train, y_pred))\n",
    "print('roc_auc for train data : ',metrics.roc_auc_score(y_train, y_pred))\n",
    "print('average_precision train data : ',metrics.average_precision_score(y_train, y_pred))\n",
    "print('accuracy train data : ',metrics.accuracy_score(y_train, y_pred))\n",
    "print('precision train data : ',metrics.precision_score(y_train, y_pred))\n",
    "print('recall train data : ',metrics.recall_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score for test data :  0.8392156862745097\n",
      "roc_auc for test data :  0.8243963963963964\n",
      "average_precision test data :  0.7808250325945241\n",
      "accuracy test data :  0.826271186440678\n",
      "precision test data :  0.823076923076923\n",
      "recall test data :  0.856\n"
     ]
    }
   ],
   "source": [
    "y_pred = rfc.predict(X_test)\n",
    "print('f1_score for test data : ',metrics.f1_score(y_test, y_pred))\n",
    "print('roc_auc for test data : ',metrics.roc_auc_score(y_test, y_pred))\n",
    "print('average_precision test data : ',metrics.average_precision_score(y_test, y_pred))\n",
    "print('accuracy test data : ',metrics.accuracy_score(y_test, y_pred))\n",
    "print('precision test data : ',metrics.precision_score(y_test, y_pred))\n",
    "print('recall test data : ',metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running this first model we have been able to observe that the accuracy of the model is 0.824; which is a good score better than the previous; however it is necessary to improve it a little more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### How to improve the accuracy of random forest?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve the score of our model there are 8 ways to improve it: \n",
    "1. **Add more data**\n",
    "2. **Treat missing and Outlier values**\n",
    "3. **Feature Engineering**\n",
    "4. **Feature Selection**\n",
    "5. **Multiple algorithms**\n",
    "6. **Algorithm Tuning**\n",
    "7. **Ensemble methods.**\n",
    "8. **Cross Validation**\n",
    "\n",
    "However throughout this challenge we have relied on three methods to boost the accuracy of a model which are the tuning algorithm, the ensemble models and cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### IMPROVING OF SCORE RANDOM FOREST WITH  HYPERPARAMETERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After our first random forest test without parameters we decided to look for an algorithm that would be able to find the performing parameters which give us the best accuracy in Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV for RandomForestClassifier\n",
      "Fitting 5 folds for each of 2052 candidates, totalling 10260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.68001518 0.69715117 0.706961   ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={'class_weight': ['balanced', 'unbalanced'],\n",
       "                         'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "                         'max_features': ['auto', 'sqrt', 'log2'],\n",
       "                         'n_estimators': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
       "                                          13, 14, 15, 16, 17, 18, 19]},\n",
       "             scoring='f1', verbose=True)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearchCV for RandomForestClassifier\n",
    "print(\"GridSearchCV for RandomForestClassifier\")\n",
    "# Create param grid.\n",
    "param_grid = {\n",
    "    'n_estimators' : list(range(1,20)),\n",
    "    'max_depth' : list(range(1,10)), \n",
    "    'class_weight': ['balanced','unbalanced'],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'criterion':['gini', 'entropy']\n",
    "    }\n",
    "scv = StratifiedKFold(n_splits=5)\n",
    "rfc_1 = GridSearchCV(rfc,param_grid = param_grid, scoring = 'f1', cv = scv, verbose=True, n_jobs=-1)\n",
    "best_rfc_1 = rfc_1.fit(X_train, y_train)\n",
    "best_rfc_1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the application of the search algorithm we have been able to find the parameters that make our model perform better at Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV f1 random forest score=0.834):\n",
      "Best model:\n",
      " {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 9, 'max_features': 'log2', 'n_estimators': 16}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameter (CV f1 random forest score=%0.3f):\" % best_rfc_1.best_score_)\n",
    "\n",
    "print(\"Best model:\\n\", best_rfc_1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
       "                       max_depth=9, max_features='log2', n_estimators=16,\n",
       "                       random_state=0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(random_state=0,class_weight='balanced',\n",
    "                             criterion= 'entropy',max_depth= 9,max_features='log2',n_estimators= 16)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score for train data :  0.9516678012253234\n",
      "roc_auc for train data :  0.9508089098717971\n",
      "average_precision train data :  0.9414104037749791\n",
      "accuracy train data :  0.9497523000707714\n",
      "precision train data :  0.9708333333333333\n",
      "recall train data :  0.9332443257676902\n"
     ]
    }
   ],
   "source": [
    "y_pred = rfc.predict(X_train)\n",
    "print('f1_score for train data : ',metrics.f1_score(y_train, y_pred))\n",
    "print('roc_auc for train data : ',metrics.roc_auc_score(y_train, y_pred))\n",
    "print('average_precision train data : ',metrics.average_precision_score(y_train, y_pred))\n",
    "print('accuracy train data : ',metrics.accuracy_score(y_train, y_pred))\n",
    "print('precision train data : ',metrics.precision_score(y_train, y_pred))\n",
    "print('recall train data : ',metrics.recall_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score for test data :  0.8286852589641432\n",
      "roc_auc for test data :  0.8169009009009008\n",
      "average_precision test data :  0.7757132095776162\n",
      "accuracy test data :  0.8177966101694916\n",
      "precision test data :  0.8253968253968254\n",
      "recall test data :  0.832\n"
     ]
    }
   ],
   "source": [
    "y_pred = rfc.predict(X_test)\n",
    "print('f1_score for test data : ',metrics.f1_score(y_test, y_pred))\n",
    "print('roc_auc for test data : ',metrics.roc_auc_score(y_test, y_pred))\n",
    "print('average_precision test data : ',metrics.average_precision_score(y_test, y_pred))\n",
    "print('accuracy test data : ',metrics.accuracy_score(y_test, y_pred))\n",
    "print('precision test data : ',metrics.precision_score(y_test, y_pred))\n",
    "print('recall test data : ',metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "losses prediction  :  0.18220338983050846\n",
      "confusion_matrix :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[178,  44],\n",
       "       [ 42, 208]], dtype=int64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion matrix \n",
    "c=confusion_matrix(y_test, y_pred)\n",
    "print(\"losses prediction  : \",(c[1][0] +(c[0][1]))/len(y_test))\n",
    "print(\"confusion_matrix :\")\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We increase some performances and if we widen the parameters we can have a better result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Classifier 2: Neural Network classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 1s 2ms/step - loss: 0.6302 - accuracy: 0.6265\n",
      "accuracy: 78.81%\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=12, activation='relu'))\n",
    "\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train)\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II-3.Multiclass Classfication "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem which can be solved: Seven class classifications **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Education</th>\n",
       "      <th>Country</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Neuroticism</th>\n",
       "      <th>Extraversion</th>\n",
       "      <th>Openness</th>\n",
       "      <th>Agreeableness</th>\n",
       "      <th>Conscientiousness</th>\n",
       "      <th>Impulsiveness</th>\n",
       "      <th>Sensation_seeking</th>\n",
       "      <th>Cannabis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.49788</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>-0.05921</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>0.12600</td>\n",
       "      <td>0.31287</td>\n",
       "      <td>-0.57545</td>\n",
       "      <td>-0.58331</td>\n",
       "      <td>-0.91699</td>\n",
       "      <td>-0.00665</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>-1.18084</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.07854</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>1.98437</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.67825</td>\n",
       "      <td>1.93886</td>\n",
       "      <td>1.43533</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>-0.14277</td>\n",
       "      <td>-0.71126</td>\n",
       "      <td>-0.21575</td>\n",
       "      <td>CL4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.49788</td>\n",
       "      <td>-0.48246</td>\n",
       "      <td>-0.05921</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.46725</td>\n",
       "      <td>0.80523</td>\n",
       "      <td>-0.84732</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>-1.01450</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>0.40148</td>\n",
       "      <td>CL3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.95197</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>1.16365</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>-0.14882</td>\n",
       "      <td>-0.80615</td>\n",
       "      <td>-0.01928</td>\n",
       "      <td>0.59042</td>\n",
       "      <td>0.58489</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>-1.18084</td>\n",
       "      <td>CL2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.49788</td>\n",
       "      <td>0.48246</td>\n",
       "      <td>1.98437</td>\n",
       "      <td>0.96082</td>\n",
       "      <td>-0.31685</td>\n",
       "      <td>0.73545</td>\n",
       "      <td>-1.63340</td>\n",
       "      <td>-0.45174</td>\n",
       "      <td>-0.30172</td>\n",
       "      <td>1.30612</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>-0.21575</td>\n",
       "      <td>CL3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age   Gender  Education  Country  Ethnicity  Neuroticism  Extraversion  \\\n",
       "0  0.49788  0.48246   -0.05921  0.96082    0.12600      0.31287      -0.57545   \n",
       "1 -0.07854 -0.48246    1.98437  0.96082   -0.31685     -0.67825       1.93886   \n",
       "2  0.49788 -0.48246   -0.05921  0.96082   -0.31685     -0.46725       0.80523   \n",
       "3 -0.95197  0.48246    1.16365  0.96082   -0.31685     -0.14882      -0.80615   \n",
       "4  0.49788  0.48246    1.98437  0.96082   -0.31685      0.73545      -1.63340   \n",
       "\n",
       "   Openness  Agreeableness  Conscientiousness  Impulsiveness  \\\n",
       "0  -0.58331       -0.91699           -0.00665       -0.21712   \n",
       "1   1.43533        0.76096           -0.14277       -0.71126   \n",
       "2  -0.84732       -1.62090           -1.01450       -1.37983   \n",
       "3  -0.01928        0.59042            0.58489       -1.37983   \n",
       "4  -0.45174       -0.30172            1.30612       -0.21712   \n",
       "\n",
       "   Sensation_seeking Cannabis  \n",
       "0           -1.18084      CL0  \n",
       "1           -0.21575      CL4  \n",
       "2            0.40148      CL3  \n",
       "3           -1.18084      CL2  \n",
       "4           -0.21575      CL3  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_df=df.copy()\n",
    "multi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_to_num(x):\n",
    "    \n",
    "    if (x == 'CL0') :\n",
    "        x = 0\n",
    "    if (x == 'CL1') :\n",
    "        x = 1\n",
    "    if (x == 'CL2') :\n",
    "        x = 2\n",
    "    if (x == 'CL3') :\n",
    "        x = 3\n",
    "    if (x == 'CL4') :\n",
    "        x = 4\n",
    "    if (x == 'CL5') :\n",
    "        x = 5\n",
    "    if (x == 'CL6') :\n",
    "        x = 6\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_df['Cannabis'] = multi_df['Cannabis'].map(cat_to_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = multi_df['Cannabis']\n",
    "X = multi_df.drop(['Cannabis'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 42, stratify=y)\n",
    "X_train = StandardScaler().fit_transform(X_train)\n",
    "X_test = StandardScaler().fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ML Models For Multiclass Classfication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyClassifier(strategy='most_frequent')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy test data :  0.2457627118644068\n"
     ]
    }
   ],
   "source": [
    "y_pred =dummy_clf.predict(X_test)\n",
    "print('accuracy test data : ',metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Classifier 1 : Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train data :  1.0\n",
      "accuracy test data :  0.3919491525423729\n"
     ]
    }
   ],
   "source": [
    "y_pred = rfc.predict(X_train)\n",
    "print('accuracy train data : ',metrics.accuracy_score(y_train, y_pred))\n",
    "y_pred = rfc.predict(X_test)\n",
    "print('accuracy test data : ',metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[66,  9, 14,  4,  0,  1,  9],\n",
       "       [31,  8,  7,  0,  0,  1,  5],\n",
       "       [28,  3, 10,  1,  0,  2, 23],\n",
       "       [ 6,  1,  6,  4,  0,  4, 32],\n",
       "       [ 4,  1,  4,  1,  0,  2, 23],\n",
       "       [ 3,  1,  7,  1,  0,  2, 32],\n",
       "       [ 2,  3,  6,  6,  0,  4, 95]], dtype=int64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV for RandomForestClassifier\n",
      "Fitting 5 folds for each of 1026 candidates, totalling 5130 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={'class_weight': ['balanced'],\n",
       "                         'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "                         'max_features': ['auto', 'sqrt', 'log2'],\n",
       "                         'n_estimators': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
       "                                          13, 14, 15, 16, 17, 18, 19]},\n",
       "             verbose=True)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearchCV for RandomForestClassifier\n",
    "print(\"GridSearchCV for RandomForestClassifier\")\n",
    "# Create param grid.\n",
    "param_grid = {\n",
    "    'n_estimators' : list(range(1,20)),\n",
    "    'max_depth' : list(range(1,10)), \n",
    "    'class_weight': ['balanced'],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'criterion':['gini', 'entropy']\n",
    "    }\n",
    "scv = StratifiedKFold(n_splits=5)\n",
    "rfc_grid = GridSearchCV(rfc,param_grid = param_grid, cv = scv, verbose=True, n_jobs=-1)\n",
    "best_rfc_grid = rfc_grid.fit(X_train, y_train)\n",
    "best_rfc_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV f1 random forest score=0.362):\n",
      "Best model:\n",
      " {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 9, 'max_features': 'sqrt', 'n_estimators': 17}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameter (CV f1 random forest score=%0.3f):\" % best_rfc_grid.best_score_)\n",
    "\n",
    "print(\"Best model:\\n\", best_rfc_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
       "                       max_depth=9, max_features='sqrt', n_estimators=17,\n",
       "                       random_state=0)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(random_state=0,class_weight='balanced',\n",
    "                             criterion= 'entropy',max_depth=9,max_features='sqrt',n_estimators= 17)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train data :  0.8995046001415428\n",
      "accuracy test data :  0.3389830508474576\n"
     ]
    }
   ],
   "source": [
    "y_pred = rfc.predict(X_train)\n",
    "print('accuracy train data : ',metrics.accuracy_score(y_train, y_pred))\n",
    "y_pred = rfc.predict(X_test)\n",
    "print('accuracy test data : ',metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Classifier 2 : MLPClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier()"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier()\n",
    "mlp.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train data :  0.5159235668789809\n",
      "accuracy test data :  0.4216101694915254\n"
     ]
    }
   ],
   "source": [
    "y_pred = mlp.predict(X_train)\n",
    "print('accuracy train data : ',metrics.accuracy_score(y_train, y_pred))\n",
    "y_pred = mlp.predict(X_test)\n",
    "print('accuracy test data : ',metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=MLPClassifier(), n_jobs=-1,\n",
       "             param_grid={'activation': ['tanh', 'relu'],\n",
       "                         'alpha': [0.0001, 0.05],\n",
       "                         'hidden_layer_sizes': [(10, 30, 10), (20,)],\n",
       "                         'learning_rate': ['constant', 'adaptive'],\n",
       "                         'solver': ['sgd', 'adam']})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearchCV for MLPClassifier\n",
    "parameter_space = {\n",
    "    'hidden_layer_sizes': [(10,30,10),(20,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "}\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "clf = GridSearchCV(mlp, parameter_space, n_jobs=-1, cv=5)\n",
    "clf.fit(X_train, y_train) # X is train samples and y is the corresponding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train data :  0.42179759377211606\n",
      "accuracy test data :  0.4173728813559322\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_train)\n",
    "print('accuracy train data : ',metrics.accuracy_score(y_train, y_pred))\n",
    "y_pred = clf.predict(X_test)\n",
    "print('accuracy test data : ',metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Classifier 3 : KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train data :  0.5966029723991507\n",
      "accuracy test data :  0.3432203389830508\n"
     ]
    }
   ],
   "source": [
    "y_pred = neigh.predict(X_train)\n",
    "print('accuracy train data : ',metrics.accuracy_score(y_train, y_pred))\n",
    "y_pred = neigh.predict(X_test)\n",
    "print('accuracy test data : ',metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=KNeighborsClassifier(n_neighbors=3),\n",
       "             param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
       "                                         13, 14, 15, 16, 17, 18, 19, 20, 21, 22,\n",
       "                                         23, 24, 25, 26, 27, 28, 29, 30],\n",
       "                         'weights': ['uniform', 'distance']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearchCV for KNeighborsClassifier\n",
    "k_range = list(range(1,31))\n",
    "weight_options = [\"uniform\", \"distance\"]\n",
    "scv = StratifiedKFold(n_splits=5)\n",
    "param_grid = dict(n_neighbors = k_range, weights = weight_options)\n",
    "#print (param_grid)\n",
    "grid = GridSearchCV(neigh, param_grid, cv = scv, scoring = 'accuracy')\n",
    "grid.fit(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train data :  0.5322009907997169\n",
      "accuracy test data :  0.5190677966101694\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid.predict(X_train)\n",
    "print('accuracy train data : ',metrics.accuracy_score(y_train, y_pred))\n",
    "y_pred = grid.predict(X_test)\n",
    "print('accuracy test data : ',metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Classifier 4 : ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier()"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "extra = ExtraTreesClassifier()\n",
    "extra.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train data :  1.0\n",
      "accuracy test data :  0.3919491525423729\n"
     ]
    }
   ],
   "source": [
    "y_pred = extra.predict(X_train)\n",
    "print('accuracy train data : ',metrics.accuracy_score(y_train, y_pred))\n",
    "y_pred = extra.predict(X_test)\n",
    "print('accuracy test data : ',metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 972 candidates, totalling 2916 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.35244161 0.37154989 0.37721161 0.37933475 0.37933475 0.37933475\n",
      "        nan        nan        nan 0.24557679 0.24557679 0.24557679\n",
      " 0.24557679 0.24557679 0.24557679        nan        nan        nan\n",
      " 0.37721161 0.38287332 0.39561217 0.37933475 0.37933475 0.37933475\n",
      "        nan        nan        nan 0.37154989 0.39136589 0.38499646\n",
      " 0.39844303 0.40622788 0.4069356         nan        nan        nan\n",
      " 0.24557679 0.24557679 0.24557679 0.24557679 0.24557679 0.24557679\n",
      "        nan        nan        nan 0.38358103 0.41896674 0.4069356\n",
      " 0.40268931 0.39561217 0.4019816         nan        nan        nan\n",
      " 0.35314933 0.3920736  0.38924275 0.39844303 0.39490446 0.40339703\n",
      "        nan        nan        nan 0.24557679 0.24557679 0.24557679\n",
      " 0.24557679 0.24557679 0.24557679        nan        nan        nan\n",
      " 0.39561217 0.39844303 0.4118896  0.39419674 0.39631989 0.39985846\n",
      "        nan        nan        nan 0.3665959  0.37367304 0.38924275\n",
      " 0.39631989 0.40339703 0.40127389        nan        nan        nan\n",
      " 0.24557679 0.24557679 0.24557679 0.24557679 0.24557679 0.24557679\n",
      "        nan        nan        nan 0.39348903 0.41259731 0.4069356\n",
      " 0.39419674 0.3970276  0.40339703        nan        nan        nan\n",
      " 0.36588818 0.37650389 0.38216561 0.39348903 0.40339703 0.40410474\n",
      "        nan        nan        nan 0.24557679 0.24557679 0.24557679\n",
      " 0.24557679 0.24557679 0.24557679        nan        nan        nan\n",
      " 0.38287332 0.40127389 0.40410474 0.39065817 0.39985846 0.40339703\n",
      "        nan        nan        nan 0.36447275 0.37367304 0.37367304\n",
      " 0.38570418 0.38358103 0.38641189        nan        nan        nan\n",
      " 0.24557679 0.24557679 0.24557679 0.24557679 0.24557679 0.24557679\n",
      "        nan        nan        nan 0.39278132 0.38924275 0.38924275\n",
      " 0.38428875 0.38782732 0.3871196         nan        nan        nan\n",
      " 0.38428875 0.38145789 0.38287332 0.37508846 0.37933475 0.37933475\n",
      "        nan        nan        nan 0.24557679 0.24557679 0.24557679\n",
      " 0.24557679 0.24557679 0.24557679        nan        nan        nan\n",
      " 0.37933475 0.38428875 0.38075018 0.37933475 0.37933475 0.37933475\n",
      "        nan        nan        nan 0.39844303 0.40410474 0.4069356\n",
      " 0.38782732 0.40127389 0.40410474        nan        nan        nan\n",
      " 0.24557679 0.24557679 0.24557679 0.24557679 0.24557679 0.24557679\n",
      "        nan        nan        nan 0.39136589 0.39490446 0.40552017\n",
      " 0.39278132 0.40056617 0.40481246        nan        nan        nan\n",
      " 0.40552017 0.40905874 0.39631989 0.39490446 0.40410474 0.40481246\n",
      "        nan        nan        nan 0.24557679 0.24557679 0.24557679\n",
      " 0.24557679 0.24557679 0.24557679        nan        nan        nan\n",
      " 0.39631989 0.40552017 0.40622788 0.3920736  0.40481246 0.40905874\n",
      "        nan        nan        nan 0.40410474 0.4019816  0.4019816\n",
      " 0.39490446 0.39631989 0.40835103        nan        nan        nan\n",
      " 0.24557679 0.24557679 0.24557679 0.24557679 0.24557679 0.24557679\n",
      "        nan        nan        nan 0.39773531 0.40056617 0.40622788\n",
      " 0.39773531 0.39136589 0.40764331        nan        nan        nan\n",
      " 0.39773531 0.40552017 0.40410474 0.39065817 0.39915074 0.39985846\n",
      "        nan        nan        nan 0.24557679 0.24557679 0.24557679\n",
      " 0.24557679 0.24557679 0.24557679        nan        nan        nan\n",
      " 0.39561217 0.40552017 0.40622788 0.41118188 0.39985846 0.40835103\n",
      "        nan        nan        nan 0.38924275 0.39065817 0.39419674\n",
      " 0.38499646 0.38428875 0.38853503        nan        nan        nan\n",
      " 0.24557679 0.24557679 0.24557679 0.24557679 0.24557679 0.24557679\n",
      "        nan        nan        nan 0.38641189 0.38853503 0.38995046\n",
      " 0.38358103 0.38499646 0.38499646        nan        nan        nan\n",
      " 0.40764331 0.40552017 0.40835103 0.37933475 0.37933475 0.37933475\n",
      "        nan        nan        nan 0.24557679 0.24557679 0.24557679\n",
      " 0.24557679 0.24557679 0.24557679        nan        nan        nan\n",
      " 0.39561217 0.41047417 0.40481246 0.37933475 0.37933475 0.37933475\n",
      "        nan        nan        nan 0.40552017 0.40056617 0.41047417\n",
      " 0.39136589 0.4019816  0.40835103        nan        nan        nan\n",
      " 0.24557679 0.24557679 0.24557679 0.24557679 0.24557679 0.24557679\n",
      "        nan        nan        nan 0.40552017 0.40835103 0.40835103\n",
      " 0.40339703 0.40905874 0.40127389        nan        nan        nan\n",
      " 0.39985846 0.40552017 0.40835103 0.3920736  0.39561217 0.39773531\n",
      "        nan        nan        nan 0.24557679 0.24557679 0.24557679\n",
      " 0.24557679 0.24557679 0.24557679        nan        nan        nan\n",
      " 0.40552017 0.40622788 0.40764331 0.39915074 0.39985846 0.40552017\n",
      "        nan        nan        nan 0.40622788 0.40622788 0.40835103\n",
      " 0.3970276  0.40339703 0.40764331        nan        nan        nan\n",
      " 0.24557679 0.24557679 0.24557679 0.24557679 0.24557679 0.24557679\n",
      "        nan        nan        nan 0.40481246 0.39773531 0.40764331\n",
      " 0.39136589 0.39773531 0.40268931        nan        nan        nan\n",
      " 0.40056617 0.4069356  0.40835103 0.40410474 0.40339703 0.3970276\n",
      "        nan        nan        nan 0.24557679 0.24557679 0.24557679\n",
      " 0.24557679 0.24557679 0.24557679        nan        nan        nan\n",
      " 0.40481246 0.4069356  0.41047417 0.39915074 0.40410474 0.40764331\n",
      "        nan        nan        nan 0.40268931 0.4069356  0.4069356\n",
      " 0.38782732 0.38853503 0.38570418        nan        nan        nan\n",
      " 0.24557679 0.24557679 0.24557679 0.24557679 0.24557679 0.24557679\n",
      "        nan        nan        nan 0.40622788 0.40410474 0.41047417\n",
      " 0.39915074 0.38358103 0.3871196         nan        nan        nan\n",
      " 0.33828733 0.34253362 0.33404105 0.38145789 0.38075018 0.38004246\n",
      "        nan        nan        nan 0.24557679 0.24557679 0.24557679\n",
      " 0.24557679 0.24557679 0.24557679        nan        nan        nan\n",
      " 0.36942675 0.36588818 0.3665959  0.38004246 0.38287332 0.38145789\n",
      "        nan        nan        nan 0.35598018 0.37438075 0.38004246\n",
      " 0.39348903 0.3970276  0.40339703        nan        nan        nan\n",
      " 0.24557679 0.24557679 0.24557679 0.24557679 0.24557679 0.24557679\n",
      "        nan        nan        nan 0.39915074 0.4019816  0.40410474\n",
      " 0.40339703 0.40622788 0.40410474        nan        nan        nan\n",
      " 0.35598018 0.36518047 0.37650389 0.39985846 0.39348903 0.40622788\n",
      "        nan        nan        nan 0.24557679 0.24557679 0.24557679\n",
      " 0.24557679 0.24557679 0.24557679        nan        nan        nan\n",
      " 0.39348903 0.40481246 0.40339703 0.39773531 0.40552017 0.41047417\n",
      "        nan        nan        nan 0.35031847 0.35244161 0.37862703\n",
      " 0.40481246 0.40056617 0.40410474        nan        nan        nan\n",
      " 0.24557679 0.24557679 0.24557679 0.24557679 0.24557679 0.24557679\n",
      "        nan        nan        nan 0.38853503 0.40905874 0.39985846\n",
      " 0.39844303 0.40410474 0.40905874        nan        nan        nan\n",
      " 0.35810333 0.3616419  0.37579618 0.4019816  0.40339703 0.40622788\n",
      "        nan        nan        nan 0.24557679 0.24557679 0.24557679\n",
      " 0.24557679 0.24557679 0.24557679        nan        nan        nan\n",
      " 0.39065817 0.39985846 0.39844303 0.4019816  0.40339703 0.4069356\n",
      "        nan        nan        nan 0.34465676 0.36093418 0.36447275\n",
      " 0.39490446 0.39844303 0.4019816         nan        nan        nan\n",
      " 0.24557679 0.24557679 0.24557679 0.24557679 0.24557679 0.24557679\n",
      "        nan        nan        nan 0.37013447 0.37862703 0.38075018\n",
      " 0.40339703 0.38428875 0.39490446        nan        nan        nan\n",
      " 0.3871196  0.38216561 0.38428875 0.38287332 0.37933475 0.38145789\n",
      "        nan        nan        nan 0.24557679 0.24557679 0.24557679\n",
      " 0.24557679 0.24557679 0.24557679        nan        nan        nan\n",
      " 0.38641189 0.38570418 0.38358103 0.38287332 0.37933475 0.38145789\n",
      "        nan        nan        nan 0.39773531 0.40622788 0.40622788\n",
      " 0.39348903 0.40552017 0.40481246        nan        nan        nan\n",
      " 0.24557679 0.24557679 0.24557679 0.24557679 0.24557679 0.24557679\n",
      "        nan        nan        nan 0.4019816  0.3970276  0.40339703\n",
      " 0.40056617 0.40552017 0.40622788        nan        nan        nan\n",
      " 0.3970276  0.40905874 0.40339703 0.40410474 0.40127389 0.40410474\n",
      "        nan        nan        nan 0.24557679 0.24557679 0.24557679\n",
      " 0.24557679 0.24557679 0.24557679        nan        nan        nan\n",
      " 0.39561217 0.40905874 0.40622788 0.39136589 0.40056617 0.4019816\n",
      "        nan        nan        nan 0.4019816  0.40481246 0.4069356\n",
      " 0.39136589 0.40481246 0.40410474        nan        nan        nan\n",
      " 0.24557679 0.24557679 0.24557679 0.24557679 0.24557679 0.24557679\n",
      "        nan        nan        nan 0.40056617 0.39985846 0.40410474\n",
      " 0.39631989 0.40622788 0.40056617        nan        nan        nan\n",
      " 0.40268931 0.40339703 0.40622788 0.40056617 0.40127389 0.40764331\n",
      "        nan        nan        nan 0.24557679 0.24557679 0.24557679\n",
      " 0.24557679 0.24557679 0.24557679        nan        nan        nan\n",
      " 0.3970276  0.4019816  0.40552017 0.40127389 0.4069356  0.40622788\n",
      "        nan        nan        nan 0.38995046 0.39065817 0.39065817\n",
      " 0.3871196  0.40268931 0.39773531        nan        nan        nan\n",
      " 0.24557679 0.24557679 0.24557679 0.24557679 0.24557679 0.24557679\n",
      "        nan        nan        nan 0.38853503 0.3920736  0.39490446\n",
      " 0.3920736  0.39348903 0.39490446        nan        nan        nan\n",
      " 0.40339703 0.40056617 0.40622788 0.37933475 0.38216561 0.38145789\n",
      "        nan        nan        nan 0.24557679 0.24557679 0.24557679\n",
      " 0.24557679 0.24557679 0.24557679        nan        nan        nan\n",
      " 0.40764331 0.40552017 0.40268931 0.38145789 0.38287332 0.38145789\n",
      "        nan        nan        nan 0.4019816  0.4118896  0.41118188\n",
      " 0.39490446 0.40764331 0.40339703        nan        nan        nan\n",
      " 0.24557679 0.24557679 0.24557679 0.24557679 0.24557679 0.24557679\n",
      "        nan        nan        nan 0.40056617 0.41047417 0.40905874\n",
      " 0.40056617 0.40622788 0.40481246        nan        nan        nan\n",
      " 0.41047417 0.40764331 0.40905874 0.39844303 0.40835103 0.40622788\n",
      "        nan        nan        nan 0.24557679 0.24557679 0.24557679\n",
      " 0.24557679 0.24557679 0.24557679        nan        nan        nan\n",
      " 0.40622788 0.41047417 0.40835103 0.39773531 0.40410474 0.40622788\n",
      "        nan        nan        nan 0.4069356  0.40552017 0.41118188\n",
      " 0.4019816  0.39915074 0.4069356         nan        nan        nan\n",
      " 0.24557679 0.24557679 0.24557679 0.24557679 0.24557679 0.24557679\n",
      "        nan        nan        nan 0.4069356  0.40764331 0.40552017\n",
      " 0.40268931 0.40976645 0.40622788        nan        nan        nan\n",
      " 0.40764331 0.40339703 0.40622788 0.40127389 0.40268931 0.40481246\n",
      "        nan        nan        nan 0.24557679 0.24557679 0.24557679\n",
      " 0.24557679 0.24557679 0.24557679        nan        nan        nan\n",
      " 0.40056617 0.40622788 0.40552017 0.40268931 0.39985846 0.40552017\n",
      "        nan        nan        nan 0.41118188 0.40905874 0.40622788\n",
      " 0.39561217 0.39985846 0.4019816         nan        nan        nan\n",
      " 0.24557679 0.24557679 0.24557679 0.24557679 0.24557679 0.24557679\n",
      "        nan        nan        nan 0.40056617 0.40268931 0.40622788\n",
      " 0.40056617 0.39278132 0.39490446        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=ExtraTreesClassifier(), n_jobs=-1,\n",
       "             param_grid={'bootstrap': [True, False], 'max_depth': [None, 2, 5],\n",
       "                         'max_features': [None, 'sqrt', 'auto', 'log2', 0.3,\n",
       "                                          0.5],\n",
       "                         'min_samples_leaf': [1, 0.5, 2],\n",
       "                         'min_samples_split': [2, 0.5, 1],\n",
       "                         'n_estimators': [20, 50, 100]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearchCV for KNeighborsClassifier\n",
    "params = {'n_estimators': [20,50,100],\n",
    "          'max_depth': [None, 2, 5,],\n",
    "          'min_samples_split': [2, 0.5,1 ],\n",
    "          'min_samples_leaf': [1, 0.5, 2 ],\n",
    "          'max_features': [None, 'sqrt', 'auto', 'log2', 0.3,0.5],\n",
    "          'bootstrap':[True, False]\n",
    "         }\n",
    "\n",
    "ef_classifier_grid = GridSearchCV(extra, param_grid=params, n_jobs=-1, cv=3, verbose=1)\n",
    "ef_classifier_grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train data :  0.8209483368719037\n",
      "accuracy test data :  0.4110169491525424\n"
     ]
    }
   ],
   "source": [
    "y_pred = ef_classifier_grid.predict(X_train)\n",
    "print('accuracy train data : ',metrics.accuracy_score(y_train, y_pred))\n",
    "y_pred = ef_classifier_grid.predict(X_test)\n",
    "print('accuracy test data : ',metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Classifier 5 : GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier()"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gdc = GradientBoostingClassifier()\n",
    "gdc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train data :  0.7438075017692852\n",
      "accuracy test data :  0.3771186440677966\n"
     ]
    }
   ],
   "source": [
    "y_pred = gdc.predict(X_train)\n",
    "print('accuracy train data : ',metrics.accuracy_score(y_train, y_pred))\n",
    "y_pred = gdc.predict(X_test)\n",
    "print('accuracy test data : ',metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# GridSearchCV for KNeighborsClassifier\n",
    "parameters = {\n",
    "    \"loss\":[\"deviance\"],\n",
    "    \"learning_rate\": [0.01,  0.1, 0.15, 0.2],\n",
    "    \"min_samples_split\": np.linspace(0.1, 0.5,2),\n",
    "    \"min_samples_leaf\": np.linspace(0.1, 0.5,2),\n",
    "    \"max_depth\":[3,5,8],\n",
    "    \"max_features\":[\"log2\",\"sqrt\"],\n",
    "    \"n_estimators\":[3]\n",
    "    }\n",
    "\n",
    "clf = GridSearchCV(gdc, parameters, cv=10, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy train data :  0.4083510261854211\n",
      "accuracy test data :  0.4152542372881356\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_train)\n",
    "print('accuracy train data : ',metrics.accuracy_score(y_train, y_pred))\n",
    "y_pred = clf.predict(X_test)\n",
    "print('accuracy test data : ',metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Classifier 6 : Stacking classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Moi\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Moi\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Moi\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Moi\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Moi\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Moi\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Moi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4004237288135593"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "estimators = [('rf', rfc),('mlp', mlp),('gdc', gdc),('extra',extra),('neigh',neigh),('grid',grid)]\n",
    "\n",
    "clf = StackingClassifier( estimators=estimators, final_estimator=LogisticRegression())\n",
    "\n",
    "clf.fit(X_train, y_train).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Classifier 6 : OneVsOneClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_model=[rfc, mlp, grid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier()\n",
      "accuracy test data :  0.4067796610169492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Moi\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Moi\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Moi\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Moi\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Moi\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Moi\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Moi\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Moi\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Moi\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Moi\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Moi\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Moi\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Moi\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Moi\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Moi\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Moi\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Moi\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Moi\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Moi\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Moi\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Moi\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier()\n",
      "accuracy test data :  0.4343220338983051\n",
      "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
      "             estimator=KNeighborsClassifier(n_neighbors=3),\n",
      "             param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
      "                                         13, 14, 15, 16, 17, 18, 19, 20, 21, 22,\n",
      "                                         23, 24, 25, 26, 27, 28, 29, 30],\n",
      "                         'weights': ['uniform', 'distance']},\n",
      "             scoring='accuracy')\n",
      "accuracy test data :  0.3898305084745763\n"
     ]
    }
   ],
   "source": [
    "for model in list_model :\n",
    "    # define ovo strategy\n",
    "    ovo = OneVsOneClassifier(model)\n",
    "    # fit model\n",
    "    ovo.fit(X_train, y_train)\n",
    "    y_pred = ovo.predict(X_test)\n",
    "    print(model)\n",
    "    print('accuracy test data : ',metrics.accuracy_score(y_test, y_pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Classifier 7 : OneVsOneClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier()\n",
      "accuracy test data :  0.4067796610169492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Moi\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Moi\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Moi\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Moi\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Moi\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Moi\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Moi\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier()\n",
      "accuracy test data :  0.4194915254237288\n",
      "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
      "             estimator=KNeighborsClassifier(n_neighbors=3),\n",
      "             param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
      "                                         13, 14, 15, 16, 17, 18, 19, 20, 21, 22,\n",
      "                                         23, 24, 25, 26, 27, 28, 29, 30],\n",
      "                         'weights': ['uniform', 'distance']},\n",
      "             scoring='accuracy')\n",
      "accuracy test data :  0.3940677966101695\n"
     ]
    }
   ],
   "source": [
    "for model in list_model :\n",
    "    # define ovo strategy\n",
    "    ovr = OneVsRestClassifier(model)\n",
    "    # fit model\n",
    "    ovr.fit(X_train, y_train)\n",
    "    y_pred = ovr.predict(X_test)\n",
    "    print(model)\n",
    "    print('accuracy test data : ',metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Conclusion :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Drug_consumption dataset we tried two solutions:<br>\n",
    "**-binary classfication **: <br>we consider that the classes \"Never Used\", \"Used over a Decade Ago\", \"Used in Last Decade\" as non user and the rest as drug consumer, we apply some models and apply cross validations to increase the performance of these models and in the end we found a score of 84%.<br>\n",
    "**-Multiclass classfication**: <br>We consider the 7 classes : <br>\n",
    "CL0 Never Used <br>\n",
    "CL1 Used over a Decade Ago <br>\n",
    "CL2 Used in Last Decade <br>\n",
    "CL3 Used in Last Year <br>\n",
    "CL4 Used in Last Month<br>\n",
    "CL5 Used in Last Week <br>\n",
    "CL6 Used in Last Day <br>\n",
    "We tried many models and techniques to increase the accuracy but the best score we got was 51%.<br>\n",
    "we could not get a score higher than 51% because the volume of our dataset is not big enough so that we have for some classes little volume which prevents to have enough performances.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
